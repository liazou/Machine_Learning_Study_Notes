{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System\n",
    "\n",
    "## Methods\n",
    "\n",
    "- Popularity based: suggest popular dresses by purchase count\n",
    "- Classification: classifier will give a binary value of that product liked by this user or not\n",
    "- Collaborative Filtering\n",
    " - Nearest Neighbor Filter:\n",
    "   - User based: Find the users who have similar taste of products as the current user\n",
    "   - Item based: Recommend Items that are similar to the item user bought\n",
    " - Matrix Factorization: http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/\n",
    "\n",
    "## Features\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/221783604\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/99259582\n",
    "\n",
    "### Original Features\n",
    "- 用户的固有属性：性别，年龄，地域，学历，职业，注册时间\n",
    "- 用户的历史行为：最近阅读的文章、最近有效展示但未阅读的文章、最近的其它对文章的正负反馈行为如点赞、评论、转发、收藏、不喜欢\n",
    "- 用户所处环境特征：当前时间、推荐场景、网络类型、当前地域等\n",
    "- 商品、文章的特征：关键词、类别、发布时间\n",
    "\n",
    "### Derived Features\n",
    "- 为了区分新用户和老用户，可以构造用户注册时间（分段），用户（过去一周，过去一个月）活跃度（根据打开app次数，停留时长等分段）特征，以及他们与文章特征的交叉特征。\n",
    "- 为了区分新老文章，可以引入文章的发布时间（分布到当前时间差并分段），文章的累计和最近（比如最近1天，一周）的展示点击阅读时长数量，以及他们与文章关键、文章类型、用户关键词等的交叉特征。\n",
    "- 为了区分文章的质量，可以引入文章最近阅读时长，平均阅读时长，点击展示比，完播次数与完播率，点赞转发评论数量等特征。\n",
    "- 为了区分用户的阅读习惯，可以引入用户不同时间段（比如早中晚，周日，周末）最近阅读的数量和时长，用户最近阅读的文章的质量等。\n",
    "\n",
    "### Important Features\n",
    "- 用户长短期关键词和文章关键词，及他们的交叉（衡量用户画像与文章匹配情况）\n",
    "- 用户最近阅读文章关键词、类别及与当前文章关键词、类别的交叉（衡量用户最近阅读偏好与文章匹配情况）\n",
    "- 文章最近的点击展示时长量统计特征（衡量文章的质量与热度）\n",
    "- 相似文章的点展时长量统计特征（文章冷启动）\n",
    "- 相似用户的最近阅读文章类型、关键词特征（用户冷启动）\n",
    "- 用户最近点赞分享评论文章类别、关键词（强正反馈）\n",
    "- 用户负反馈及连续推而不点的文章标题、内容关键词（强负反馈）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/67287992![image.png](attachment:image.png)\n",
    "\n",
    "### Offline\n",
    "- precision @top k\n",
    "- AUC-ROC\n",
    "- DCG, $r_i$ = $I$(user likes the $i^{th}$ product)\n",
    "\n",
    "$$DCG = \\sum_{i=1}^p \\frac{r_i}{log_2 (i+1)}, NDCG@k = \\frac{DCG}{iDCG}$$\n",
    "\n",
    "### Online\n",
    "- input data distribution, real-time performance, variety, personality\n",
    "- diversity: whether the model recommends same items all the time\n",
    "- coverage = % items in training data recommended on test set\n",
    "- personalization = 1 - avg(cos sim between users)\n",
    "\n",
    "### Why if offline and online results are different?\n",
    "- latency of time-dependent feature updates\n",
    "- whether train and test sets overlap\n",
    "- overfitting\n",
    "\n",
    "### Whay happened if data shifts?\n",
    "- monitor real-time performance\n",
    "- trigger retraining if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold-Start User\n",
    "\n",
    "### Content-based filtering\n",
    "- utilize metadata about the new product\n",
    "- additional info from user\n",
    "- advantage:\n",
    "  - independent of user\n",
    "  - data sparsity does not arise\n",
    "  - can suggest new items to users\n",
    "\n",
    "### Popularity-based\n",
    "- product on the list which almost all new customers buy\n",
    "- disadvantage: lack of personalization\n",
    "\n",
    "### Multi-Armed Bandit Model (Reinforcement Learning)\n",
    "- find the product that maximizes the gain $\\mu_j + \\sqrt{\\frac{ln(t)}{t_j}}$\n",
    "- tradeoff between exploration and exploitation\n",
    "  - exploitation: If we found a new item that sells well, we want to show it to users more\n",
    "  - exploration: want to show others which have not been shown as much, because they can be even more popular than the items you have shown already\n",
    "\n",
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Job Recommendation\n",
    "\n",
    "### 1. How to Collect Labels?\n",
    "Collecting labels is crucial for training supervised machine learning models. In a job recommendation system, labels might represent whether a job recommendation was relevant or whether a candidate applied for or was hired for a job.\n",
    "\n",
    "**Approaches:**\n",
    "- **Historical Data:** Use historical data where resumes are matched with jobs the candidates applied to or were hired for. These applications or hires can serve as positive labels.\n",
    "- **User Feedback:** Incorporate explicit feedback from users (e.g., thumbs up/down on a recommendation, ratings, or preferences). This feedback can be treated as positive or negative labels.\n",
    "- **Implicit Feedback:** Analyze user behavior, such as clicks on job recommendations, time spent viewing job details, or application submissions. Positive behavior can be used as positive labels, while the absence of interaction can be negative or neutral labels.\n",
    "- **Expert Annotation:** If historical data is limited, you might use domain experts to manually label data, though this is time-consuming and expensive.\n",
    "\n",
    "### 2. How to Select Features?\n",
    "\n",
    "**Potential Features:**\n",
    "- **Resume-Based Features:**\n",
    "  - **Skills:** Extract skills from the resume using NLP techniques like Named Entity Recognition (NER).\n",
    "  - **Experience:** Quantify the years of experience in specific industries or roles.\n",
    "  - **Education:** Degree level, fields of study, and institutions attended.\n",
    "  - **Past Roles and Companies:** Titles held, companies worked at, and the hierarchy of positions.\n",
    "  - **Location:** Current location of the candidate, willingness to relocate, or work remotely.\n",
    "  \n",
    "- **Job-Based Features:**\n",
    "  - **Job Title:** The title of the job and its similarity to the candidate's past job titles.\n",
    "  - **Required Skills:** A match between required skills and the candidate’s skills.\n",
    "  - **Location:** Proximity of the job location to the candidate's location.\n",
    "  - **Industry:** Match between the candidate's previous industry experience and the industry of the job.\n",
    "\n",
    "- **Interaction Features:**\n",
    "  - **Click-Through Rate (CTR):** Previous interaction history with similar jobs.\n",
    "  - **Application History:** Whether the candidate has applied for similar jobs in the past.\n",
    "\n",
    "### 3. What ML Models are Appropriate to Solve the Problems?\n",
    "\n",
    "**Models:**\n",
    "- **Content-Based Filtering:** Recommends jobs based on the similarity between the resume and job descriptions. This can involve vectorizing text features using methods like TF-IDF or word embeddings (e.g., Word2Vec, BERT) and then computing cosine similarity.\n",
    "  \n",
    "- **Collaborative Filtering:** Uses past interactions to recommend jobs based on what similar candidates have applied to or been hired for. This can be done using matrix factorization techniques (e.g., SVD) or deep learning methods (e.g., Neural Collaborative Filtering).\n",
    "\n",
    "- **Hybrid Models:** Combine content-based and collaborative filtering to leverage both resume content and interaction history.\n",
    "\n",
    "- **Deep Learning Models:** \n",
    "  - **Deep Neural Networks (DNNs):** For feature-rich environments, DNNs can be trained to learn complex relationships between features.\n",
    "  - **Siamese Networks:** Can be used to learn similarity between resumes and job descriptions by comparing pairs.\n",
    "  - **Transformer Models:** Pre-trained language models like BERT can be fine-tuned to understand and match resumes with job descriptions.\n",
    "    - Concatenate tabular features into a sentence/sequence (e.g. “NYU, Math, Masters, Amazon, Applied Scientist, 4 YOE, LinkedIn, MLE, Senior”)\n",
    "\n",
    "### 4. How to Conduct A/B Test Experiments? What Metrics Can Be Used?\n",
    "\n",
    "**Steps:**\n",
    "- **Randomization:** Randomly assign users to different groups, where one group receives recommendations from the new model and the other from the baseline model.\n",
    "- **Duration:** Run the experiment for a sufficient duration to gather enough data for statistical significance.\n",
    "  \n",
    "**Metrics:**\n",
    "- **Click-Through Rate (CTR):** The percentage of job recommendations clicked by users.\n",
    "- **Conversion Rate:** The percentage of recommendations that result in a job application.\n",
    "- **Time to First Interaction:** How quickly users interact with the recommended jobs.\n",
    "- **User Engagement:** Metrics like session duration, number of job views, etc.\n",
    "- **Long-Term Metrics:** Job acceptance rate, user retention, and satisfaction surveys.\n",
    "\n",
    "### 5. How to Evaluate Online and Offline Performance During Experiments?\n",
    "\n",
    "**Offline Evaluation:**\n",
    "- **Precision@k and Recall@k:** Measure how many of the top-k recommendations are relevant.\n",
    "- **Mean Reciprocal Rank (MRR):** Evaluates how high the first relevant recommendation is ranked.\n",
    "- **Area Under the Curve (AUC):** AUC-ROC measures the trade-off between true positive rate and false positive rate.\n",
    "- **Cross-Validation:** Use cross-validation on historical data to assess model performance before deployment.\n",
    "\n",
    "**Online Evaluation:**\n",
    "- **Real-Time Metrics:** Track metrics like CTR, conversion rate, and user engagement in real-time.\n",
    "- **A/B Testing:** Compare performance metrics between different models in the live environment.\n",
    "- **User Feedback:** Collect and analyze qualitative feedback from users to identify potential improvements.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
